{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import sys as sys\n",
    "import re as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as json\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.min_rows = None\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "from config import RANDOM_STATE, MATERIALS_PATH, RESULTS_PATH\n",
    "\n",
    "GENE_SYMBOL_EFFECT_SIZE = MATERIALS_PATH.joinpath('capstone_body_weight_Statistical_effect_size_analysis_genotype_early_adult_scaled_13022023_gene_symbol_harmonized.pkl')\n",
    "PROTEIN_SEQUENCE_PATH = MATERIALS_PATH.joinpath('gene_symbol_protein_sequences.pkl')\n",
    "EXON_SEQUENCE_PATH = MATERIALS_PATH.joinpath('gene_symbol_dna_sequence_exon.pkl')\n",
    "UNSPLICED_SEQUENCE_PATH = MATERIALS_PATH.joinpath('gene_symbol_dna_sequence_unspliced.pkl')\n",
    "\n",
    "FRAC = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(GENE_SYMBOL_EFFECT_SIZE)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['est_m_ea']].agg('mean')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.sample(frac=FRAC, random_state=RANDOM_STATE)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=RANDOM_STATE).fit(df[['est_m_ea']].to_numpy())\n",
    "\n",
    "df['class'] = kmeans.labels_\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_effect_size = df.copy()\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(PROTEIN_SEQUENCE_PATH)\n",
    "\n",
    "df = df.rename({'seq': 'sequence'}, axis=1)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['sequence']].agg(lambda x: ' '.join(x.tolist()))\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = _df_effect_size.merge(df, how='inner')\n",
    "\n",
    "df = df[['gene_symbol_harmonized', 'est_m_ea', 'class', 'sequence']]\n",
    "\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_protein = df.copy()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(EXON_SEQUENCE_PATH)\n",
    "\n",
    "df = df.rename({'Sequence': 'sequence', 'Gene name': 'gene_symbol_harmonized'}, axis=1)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['sequence']].agg(lambda x: ' '.join(x.tolist()))\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = _df_effect_size.merge(df, how='inner')\n",
    "\n",
    "df = df[['gene_symbol_harmonized', 'est_m_ea', 'class', 'sequence']]\n",
    "\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_exon = df.copy()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(UNSPLICED_SEQUENCE_PATH)\n",
    "\n",
    "df = df.rename({'Sequence': 'sequence', 'Gene name': 'gene_symbol_harmonized'}, axis=1)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['sequence']].agg(lambda x: ' '.join(x.tolist()))\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = _df_effect_size.merge(df, how='inner')\n",
    "\n",
    "df = df[['gene_symbol_harmonized', 'est_m_ea', 'class', 'sequence']]\n",
    "\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_unspliced = df.copy()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_protein.copy()\n",
    "\n",
    "df = df.rename({'est_m_ea': 'Effect Size', 'class': 'Class'}, axis=1)\n",
    "\n",
    "df['Protein'] = ''\n",
    "\n",
    "_df_protein_strip_plot = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "df = _df_exon.copy()\n",
    "\n",
    "df = df.rename({'est_m_ea': 'Effect Size', 'class': 'Class'}, axis=1)\n",
    "\n",
    "df['Exon'] = ''\n",
    "\n",
    "_df_exon_strip_plot = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "df = _df_unspliced.copy()\n",
    "\n",
    "df = df.rename({'est_m_ea': 'Effect Size', 'class': 'Class'}, axis=1)\n",
    "\n",
    "df['Unspliced'] = ''\n",
    "\n",
    "_df_unspliced_strip_plot = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1)\n",
    "\n",
    "fig.suptitle('KMeans Clustering', fontsize='xx-large')\n",
    "fig.set_size_inches((10,4.5))\n",
    "fig.tight_layout()\n",
    "\n",
    "_ = sns.stripplot(data=_df_protein_strip_plot, x='Effect Size', y='Protein', hue=\"Class\", marker='.', jitter=True, s=2, ax=ax1, palette='tab10')\n",
    "_= ax1.legend(loc='right')\n",
    "_ = sns.stripplot(data=_df_exon_strip_plot, x='Effect Size', y='Exon', hue=\"Class\", marker='.', jitter=True, s=2,  ax=ax2, palette='tab10')\n",
    "_= ax2.legend(loc='right')\n",
    "_ = sns.stripplot(data=_df_unspliced_strip_plot, x='Effect Size', y='Unspliced', hue=\"Class\", marker='.', jitter=True, s=2,  ax=ax3, palette='tab10')\n",
    "_= ax3.legend(loc='right')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.75)\n",
    "plt.savefig(RESULTS_PATH.joinpath(f'kmeans_clustering_{FRAC}_{RANDOM_STATE}.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_density(df, ngram_range):\n",
    "\n",
    "    tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=ngram_range)\n",
    "\n",
    "    X = tfidf.fit_transform(df['sequence'].tolist())\n",
    "\n",
    "    X = X.todense()\n",
    "\n",
    "    df = pd.DataFrame(X, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "    df = df.T.copy()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=RANDOM_STATE).fit(df.to_numpy())\n",
    "\n",
    "    df['Class'] = kmeans.labels_\n",
    "\n",
    "    print(pd.Series(kmeans.labels_).value_counts())\n",
    "\n",
    "    df = df.groupby(['Class']).apply(lambda x: ((x != 0).sum().sum()/(x.shape[0] * x.shape[1]), x.index.tolist())).to_frame(name='density_features').reset_index()\n",
    "\n",
    "    df['Density'] = df.apply(lambda x: x['density_features'][0], axis=1)\n",
    "\n",
    "    df['Features'] = df.apply(lambda x: x['density_features'][1], axis=1)\n",
    "\n",
    "    df['Count'] = df['Features'].apply(lambda x: len(x))\n",
    "\n",
    "    df = df.drop(['density_features'], axis=1)\n",
    "\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_protein_features = feature_density(df=_df_protein.copy(), ngram_range=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_exon_features = feature_density(df=_df_exon.copy(), ngram_range=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_unspliced_features = feature_density(df=_df_unspliced.sample(frac=.1, random_state=RANDOM_STATE).copy(), ngram_range=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "ax1.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "ax2.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "ax2.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "fig.suptitle('Feature Density Analysis', fontsize='xx-large')\n",
    "fig.set_size_inches((20,5))\n",
    "fig.subplots_adjust(top=.85)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "sns.barplot(data=_df_protein_features.copy(), x='Class', y='Count', alpha=0.5, ax=ax1, palette='tab10')\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_title('Protein Feature Density')\n",
    "ax1_twin = ax1.twinx()\n",
    "sns.scatterplot(data=_df_protein_features, x='Class', y='Density', marker='d', label='Density', color = 'red', s=150, ax=ax1_twin, palette='tab10')\n",
    "_= ax1_twin.legend(loc='upper right')\n",
    "\n",
    "sns.barplot(data=_df_exon_features.copy(), x='Class', y='Count', alpha=0.5, ax=ax2, palette='tab10')\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_title('Exon Feature Density')\n",
    "ax2_twin = ax2.twinx()\n",
    "sns.scatterplot(data=_df_exon_features, x='Class', y='Density', marker='d', label='Density', color = 'red', s=150, ax=ax2_twin, palette='tab10')\n",
    "_= ax2_twin.legend(loc='upper right')\n",
    "\n",
    "sns.barplot(data=_df_unspliced_features.copy(), x='Class', y='Count', alpha=0.5, ax=ax3, palette='tab10')\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.set_title('Unspliced Feature Density')\n",
    "ax3_twin = ax3.twinx()\n",
    "sns.scatterplot(data=_df_unspliced_features, x='Class', y='Density', marker='d', label='Density', color = 'red', s=150, ax=ax3_twin, palette='tab10')\n",
    "_= ax3_twin.legend(loc='upper right')\n",
    "\n",
    "plt.savefig(RESULTS_PATH.joinpath(f'feature_density_analysis_{FRAC}_{RANDOM_STATE}.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tfidf_smote_estimator_grid(est_grid, X_train, y_train, analyzer, vocabulary, random_state=RANDOM_STATE):\n",
    "\n",
    "    estimator_model = {}\n",
    "\n",
    "    for est, param_grid in est_grid.items():\n",
    "        \n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('TfidfVectorizer', TfidfVectorizer(analyzer=analyzer, vocabulary=vocabulary)),\n",
    "            ('SMOTE', SMOTE(random_state=random_state)), # (Muralidhar, 2021)\n",
    "            (est.__class__.__name__, est)\n",
    "        ])\n",
    "\n",
    "        model = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=10, verbose=4)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        estimator_model[est] = model\n",
    "\n",
    "    return estimator_model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_protein_features.copy()\n",
    "\n",
    "df = df.loc[df['Density'] != df['Density'].min()]\n",
    "\n",
    "protein_vocabulary = df['Features'].sum()\n",
    "\n",
    "df = _df_protein.copy()\n",
    "\n",
    "X = df['sequence'].to_numpy()\n",
    "\n",
    "y = df['class'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE) # (Mudugandla, 2020)\n",
    "\n",
    "ngram_range = (4,4)\n",
    "\n",
    "est_grid = {\n",
    "    KNeighborsClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'KNeighborsClassifier__n_neighbors': [3, 5, 9]\n",
    "    },\n",
    "    LogisticRegression(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'LogisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    },\n",
    "    SVC(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'SVC__kernel': ['linear', 'rbf'],\n",
    "        'SVC__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'SVC__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    DummyClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range':[ngram_range],\n",
    "        'DummyClassifier__strategy': ['most_frequent']\n",
    "    },\n",
    "    DummyClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'DummyClassifier__strategy': ['uniform']\n",
    "    }\n",
    "}\n",
    "\n",
    "estimator_model = train_tfidf_smote_estimator_grid(est_grid=est_grid, X_train=X_train, y_train=y_train, analyzer='char_wb', vocabulary=protein_vocabulary)\n",
    "\n",
    "with open(RESULTS_PATH.joinpath(f'protein_{FRAC}_{RANDOM_STATE}.pkl'), 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'RANDOM_STATE': RANDOM_STATE,\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'estimator_model': estimator_model\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_exon_features.copy()\n",
    "\n",
    "df = df.loc[df['Density'] != df['Density'].min()]\n",
    "\n",
    "exon_vocabulary = df['Features'].sum()\n",
    "\n",
    "df = _df_exon.copy()\n",
    "\n",
    "X = df['sequence'].to_numpy()\n",
    "\n",
    "y = df['class'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE) # (Mudugandla, 2020)\n",
    "\n",
    "ngram_range = (10,10)\n",
    "\n",
    "est_grid = {\n",
    "    KNeighborsClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'KNeighborsClassifier__n_neighbors': [3, 5, 9]\n",
    "    },\n",
    "    LogisticRegression(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'LogisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    },\n",
    "    SVC(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'SVC__kernel': ['linear', 'rbf'],\n",
    "        'SVC__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'SVC__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    DummyClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range':[ngram_range],\n",
    "        'DummyClassifier__strategy': ['most_frequent']\n",
    "    },\n",
    "    DummyClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'DummyClassifier__strategy': ['uniform']\n",
    "    }\n",
    "}\n",
    "\n",
    "estimator_model = train_tfidf_smote_estimator_grid(est_grid=est_grid, X_train=X_train, y_train=y_train, analyzer='char_wb', vocabulary=exon_vocabulary)\n",
    "\n",
    "with open(RESULTS_PATH.joinpath(f'exon_{FRAC}_{RANDOM_STATE}.pkl'), 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'RANDOM_STATE': RANDOM_STATE,\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'estimator_model': estimator_model\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_unspliced_features.copy()\n",
    "\n",
    "df = df.loc[df['Density'] != df['Density'].min()]\n",
    "\n",
    "unspliced_vocabulary = df['Features'].sum()\n",
    "\n",
    "df = _df_unspliced.copy()\n",
    "\n",
    "X = df['sequence'].to_numpy()\n",
    "\n",
    "y = df['class'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE) # (Mudugandla, 2020)\n",
    "\n",
    "ngram_range = (12,12)\n",
    "\n",
    "est_grid = {\n",
    "    KNeighborsClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'KNeighborsClassifier__n_neighbors': [3, 5, 9]\n",
    "    },\n",
    "    LogisticRegression(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'LogisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    },\n",
    "    SVC(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'SVC__kernel': ['linear', 'rbf'],\n",
    "        'SVC__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'SVC__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    DummyClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range':[ngram_range],\n",
    "        'DummyClassifier__strategy': ['most_frequent']\n",
    "    },\n",
    "    DummyClassifier(): {\n",
    "        'TfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'TfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'DummyClassifier__strategy': ['uniform']\n",
    "    }\n",
    "}\n",
    "\n",
    "estimator_model = train_tfidf_smote_estimator_grid(est_grid=est_grid, X_train=X_train, y_train=y_train, analyzer='char_wb', vocabulary=unspliced_vocabulary)\n",
    "\n",
    "with open(RESULTS_PATH.joinpath(f'unspliced_{FRAC}_{RANDOM_STATE}.pkl'), 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'RANDOM_STATE': RANDOM_STATE,\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'estimator_model': estimator_model\n",
    "    }, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f5a67c8f338a2aa83971d908da2f9f4f3ea4b50553efdb05feea12445a21cfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
