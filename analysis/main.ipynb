{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import sys as sys\n",
    "import re as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json as json\n",
    "import pickle\n",
    "import urllib as urllib\n",
    "import zlib as zlib\n",
    "import base64 as base64\n",
    "from requests import Request, Session\n",
    "import requests\n",
    "from numpy import trapz\n",
    "import itertools\n",
    "import zlib as zlib\n",
    "import base64 as base64\n",
    "import pickle\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.min_rows = None\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "RANDOM_STATE = random.randint(0,100)\n",
    "\n",
    "DATA_PATH = pathlib.Path('/data1/home/adpatter/gene-to-phenotype-predictions/adpatter/data/')\n",
    "GENE_SYMBOL_EFFECT_SIZE = DATA_PATH.joinpath('capstone_body_weight_Statistical_effect_size_analysis_genotype_early_adult_scaled_13022023_gene_symbol_harmonized.pkl')\n",
    "PROTEIN_SEQUENCE_PATH = DATA_PATH.joinpath('gene_symbol_protein_sequences.pkl')\n",
    "EXON_SEQUENCE_PATH = DATA_PATH.joinpath('gene_symbol_dna_sequence_exon.pkl')\n",
    "UNSPLICED_SEQUENCE_PATH = DATA_PATH.joinpath('gene_symbol_dna_sequence_unspliced.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(GENE_SYMBOL_EFFECT_SIZE)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['est_m_ea']].agg('mean')\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, init=np.array([[df['est_m_ea'].min()],[0],[df['est_m_ea'].max()]]), random_state=RANDOM_STATE).fit(df[['est_m_ea']].to_numpy())\n",
    "\n",
    "df['class'] = kmeans.labels_\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_effect_size = df.copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(PROTEIN_SEQUENCE_PATH)\n",
    "\n",
    "df = df.rename({'seq': 'sequence'}, axis=1)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['sequence']].agg(lambda x: ' '.join(x.tolist()))\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = _df_effect_size.merge(df, how='inner')\n",
    "\n",
    "df = df[['gene_symbol_harmonized', 'est_m_ea', 'class', 'sequence']]\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_protein = df.copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(EXON_SEQUENCE_PATH)\n",
    "\n",
    "df = df.rename({'Sequence': 'sequence', 'Gene name': 'gene_symbol_harmonized'}, axis=1)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['sequence']].agg(lambda x: ' '.join(x.tolist()))\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = _df_effect_size.merge(df, how='inner')\n",
    "\n",
    "df = df[['gene_symbol_harmonized', 'est_m_ea', 'class', 'sequence']]\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_exon = df.copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(UNSPLICED_SEQUENCE_PATH)\n",
    "\n",
    "df = df.rename({'Sequence': 'sequence', 'Gene name': 'gene_symbol_harmonized'}, axis=1)\n",
    "\n",
    "df = df.groupby(['gene_symbol_harmonized'])[['sequence']].agg(lambda x: ' '.join(x.tolist()))\n",
    "\n",
    "df = df.reset_index()\n",
    "\n",
    "df = _df_effect_size.merge(df, how='inner')\n",
    "\n",
    "df = df[['gene_symbol_harmonized', 'est_m_ea', 'class', 'sequence']]\n",
    "\n",
    "assert not df['gene_symbol_harmonized'].duplicated().any()\n",
    "\n",
    "_df_unspliced = df.copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_protein.copy()\n",
    "\n",
    "df = df.sample(frac=.025)\n",
    "\n",
    "df = df.rename({'est_m_ea': 'Effect Size', 'class': 'Class'}, axis=1)\n",
    "\n",
    "df['Protein'] = ''\n",
    "\n",
    "_df_protein_strip_plot = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "df = _df_exon.copy()\n",
    "\n",
    "df = df.sample(frac=.025)\n",
    "\n",
    "df = df.rename({'est_m_ea': 'Effect Size', 'class': 'Class'}, axis=1)\n",
    "\n",
    "df['Exon'] = ''\n",
    "\n",
    "_df_exon_strip_plot = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "df = _df_unspliced.copy()\n",
    "\n",
    "df = df.sample(frac=.025)\n",
    "\n",
    "df = df.rename({'est_m_ea': 'Effect Size', 'class': 'Class'}, axis=1)\n",
    "\n",
    "df['Unspliced'] = ''\n",
    "\n",
    "_df_unspliced_strip_plot = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1)\n",
    "\n",
    "fig.suptitle('KMeans Clustering', fontsize='xx-large')\n",
    "fig.set_size_inches((10,5.5))\n",
    "fig.tight_layout()\n",
    "\n",
    "_ = sns.stripplot(data=_df_protein_strip_plot, x='Effect Size', y='Protein', hue=\"Class\", marker='.', jitter=True,  ax=ax1)\n",
    "_= ax1.legend(loc='right')\n",
    "_ = sns.stripplot(data=_df_exon_strip_plot, x='Effect Size', y='Exon', hue=\"Class\", marker='.', jitter=True,  ax=ax2)\n",
    "_= ax2.legend(loc='right')\n",
    "_ = sns.stripplot(data=_df_unspliced_strip_plot, x='Effect Size', y='Unspliced', hue=\"Class\", marker='.', jitter=True,  ax=ax3)\n",
    "_= ax3.legend(loc='right')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_density(df, ngram_range):\n",
    "\n",
    "    tfidf = TfidfVectorizer(analyzer='char_wb', ngram_range=ngram_range)\n",
    "\n",
    "    X = tfidf.fit_transform(df['sequence'].tolist())\n",
    "\n",
    "    X = X.todense()\n",
    "\n",
    "    df = pd.DataFrame(X, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "    df = df.T.copy()\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=RANDOM_STATE).fit(df.to_numpy())\n",
    "\n",
    "    df['Class'] = kmeans.labels_\n",
    "\n",
    "    print(pd.Series(kmeans.labels_).value_counts())\n",
    "\n",
    "    df = df.groupby(['Class']).apply(lambda x: ((x != 0).sum().sum()/(x.shape[0] * x.shape[1]), x.index.tolist())).to_frame(name='density_features').reset_index()\n",
    "\n",
    "    df['Density'] = df.apply(lambda x: x['density_features'][0], axis=1)\n",
    "\n",
    "    df['Features'] = df.apply(lambda x: x['density_features'][1], axis=1)\n",
    "\n",
    "    df['Count'] = df['Features'].apply(lambda x: len(x))\n",
    "\n",
    "    df = df.drop(['density_features'], axis=1)\n",
    "\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_protein_features = feature_density(df=_df_protein, ngram_range=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_exon_features = feature_density(df=_df_exon, ngram_range=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_unspliced_features = feature_density(df=_df_unspliced.sample(frac=.1), ngram_range=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "ax1.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "ax2.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "ax2.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "\n",
    "fig.suptitle('Feature Density Analysis', fontsize='xx-large')\n",
    "fig.set_size_inches((20,5))\n",
    "fig.subplots_adjust(top=.85)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "sns.barplot(data=_df_protein_features.copy(), x='Class', y='Count', alpha=0.5, ax=ax1)\n",
    "ax1.set_yscale(\"log\")\n",
    "ax1.set_title('Protein Feature Density')\n",
    "ax1_twin = ax1.twinx()\n",
    "sns.lineplot(data=_df_protein_features, x='Class', y='Density', marker='o', label='Density', sort=False, ax=ax1_twin)\n",
    "_= ax1_twin.legend(loc='upper right')\n",
    "\n",
    "sns.barplot(data=_df_exon_features.copy(), x='Class', y='Count', alpha=0.5, ax=ax2)\n",
    "ax2.set_yscale(\"log\")\n",
    "ax2.set_title('Exon Feature Density')\n",
    "ax2_twin = ax2.twinx()\n",
    "sns.lineplot(data=_df_exon_features, x='Class', y='Density', marker='o', label='Density', sort = False, ax=ax2_twin)\n",
    "_= ax2_twin.legend(loc='upper right')\n",
    "\n",
    "sns.barplot(data=_df_unspliced_features.copy(), x='Class', y='Count', alpha=0.5, ax=ax3)\n",
    "ax3.set_yscale(\"log\")\n",
    "ax3.set_title('Unspliced Feature Density')\n",
    "ax3_twin = ax3.twinx()\n",
    "sns.lineplot(data=_df_unspliced_features, x='Class', y='Density', marker='o', label='Density', sort = False, ax=ax3_twin)\n",
    "_= ax3_twin.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_protein_features.copy()\n",
    "\n",
    "df = df.loc[df['Density'] != df['Density'].min()]\n",
    "\n",
    "protein_vocabulary = df['Features'].sum()\n",
    "\n",
    "df = _df_exon_features.copy()\n",
    "\n",
    "df = df.loc[df['Density'] != df['Density'].min()]\n",
    "\n",
    "exon_vocabulary = df['Features'].sum()\n",
    "\n",
    "df = _df_unspliced_features.copy()\n",
    "\n",
    "df = df.loc[df['Density'] != df['Density'].min()]\n",
    "\n",
    "unspliced_vocabulary = df['Features'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(_df, ngram_range):\n",
    "\n",
    "    X = _df['sequence'].copy().to_numpy()\n",
    "    y = _df['class'].copy().to_numpy()\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    param_grid = {\n",
    "        'tfidfVectorizer__ngram_range': [ngram_range],\n",
    "        'tfidfVectorizer__norm': ('l1', 'l2'),\n",
    "        'SVC__kernel': ['linear', 'rbf'],\n",
    "        'SVC__C': [0.001,0.01,0.1,1,10,100, 1000],\n",
    "        'SVC__gamma': ['scale', 'auto']\n",
    "    }\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('tfidfVectorizer',  TfidfVectorizer(analyzer='char_wb', vocabulary=protein_vocabulary)),\n",
    "        ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "        ('SVC', SVC())\n",
    "        ])\n",
    "\n",
    "    gsSVC = GridSearchCV(estimator=pipe, param_grid=param_grid, n_jobs=3, verbose=3)\n",
    "\n",
    "    gsSVC.fit(X, y)\n",
    "\n",
    "    df = pd.DataFrame(gsSVC.cv_results_)\n",
    "\n",
    "    df['classifier'] = 'SVC'\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "\n",
    "    X = _df['sequence'].copy().to_numpy()\n",
    "    y = _df['class'].copy().to_numpy()\n",
    "    \n",
    "    param_grid = {\n",
    "        'tfidfVectorizer__ngram_range': [(4, 4)],\n",
    "        'dummyClassifier__strategy': ['uniform', 'most_frequent']\n",
    "    }\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('tfidfVectorizer',  TfidfVectorizer(analyzer='char_wb')), \n",
    "        ('smote', SMOTE(random_state=RANDOM_STATE)),\n",
    "        ('dummyClassifier', DummyClassifier())\n",
    "        ])\n",
    "\n",
    "    gsDummyClassifier = GridSearchCV(estimator=pipe, param_grid=param_grid, n_jobs=2, verbose=3)\n",
    "\n",
    "    gsDummyClassifier.fit(X, y)\n",
    "\n",
    "    df = pd.DataFrame(gsDummyClassifier.cv_results_)\n",
    "\n",
    "    df['classifier'] = 'DummyClassifier'\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    df = df.set_index(['classifier'])\n",
    "\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_protein.copy()\n",
    "\n",
    "df = process(df, (4,4))\n",
    "\n",
    "df.to_pickle('classification_protein.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_exon.copy()\n",
    "\n",
    "df = process(df, (10,10))\n",
    "\n",
    "df.to_pickle('classification_exon.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = _df_unspliced.copy()\n",
    "\n",
    "df = process(df, (12,12))\n",
    "\n",
    "df.to_pickle('classification_unspliced.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('classification_protein.pkl')\n",
    "\n",
    "df.groupby(['classifier']).apply(lambda x: x.loc[x['mean_test_score'] == x['mean_test_score'].max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'tfidfVectorizer__ngram_range': [(4, 4)],\n",
    "#     'tfidfVectorizer__norm': ('l1', 'l2'),\n",
    "#     'logisticRegression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# }\n",
    "\n",
    "# pipe = Pipeline(steps=[\n",
    "#     ('tfidfVectorizer',  TfidfVectorizer(analyzer='char_wb')), \n",
    "#     ('logisticRegression', LogisticRegression())\n",
    "#     ])\n",
    "\n",
    "# gsLogisticRegression = GridSearchCV(estimator=pipe, param_grid=param_grid, n_jobs=2, verbose=3)\n",
    "\n",
    "# gsLogisticRegression.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(gsLogisticRegression.cv_results_)\n",
    "\n",
    "# df.loc[df['mean_test_score'] == df['mean_test_score'].max()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2d6514f9963693ddf9848f840dcbc46c3e7b9abcac09ab97b6beeb9a964f0bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
